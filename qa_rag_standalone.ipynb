{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection, connections, MilvusException\n",
    "import json\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Collection config\n",
    "id = FieldSchema(\n",
    "  name=\"id\",\n",
    "  dtype=DataType.INT64,\n",
    "  is_primary=True,\n",
    "  auto_id=True\n",
    ")\n",
    "text = FieldSchema(\n",
    "  name=\"text\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  max_length=5000,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"Unknown\"\n",
    ")\n",
    "vector = FieldSchema(\n",
    "  name=\"vector\",\n",
    "  dtype=DataType.FLOAT_VECTOR,\n",
    "  dim=128\n",
    ")\n",
    "schema = CollectionSchema(\n",
    "  fields=[id, text, vector],\n",
    "  enable_dynamic_field=True\n",
    ")\n",
    "collection_name = \"Products\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to milvus server\n",
    "connections.connect(host=\"localhost\", port=\"19530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create collection\n",
    "collection = Collection(\n",
    "    name=collection_name,\n",
    "    schema=schema,\n",
    "    using='default', # Milvus server alias\n",
    "    shards_num=2 # Number of data nodes to use\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add index to vector\n",
    "index_params = {\n",
    "  \"metric_type\":\"L2\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":2}\n",
    "}\n",
    "\n",
    "from pymilvus import Collection, utility\n",
    "# Get an existing collection.\n",
    "collection = Collection(\"Products\")      \n",
    "collection.create_index(\n",
    "  field_name=\"vector\", \n",
    "  index_params=index_params\n",
    ")\n",
    "\n",
    "utility.index_building_progress(\"Products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an existing collection and load\n",
    "collection = Collection(\"Products\")      \n",
    "collection.load()\n",
    "\n",
    "# Check the loading progress and loading status\n",
    "utility.load_state(\"Products\")\n",
    "# Output: <LoadState: Loaded>\n",
    "\n",
    "utility.loading_progress(\"Products\")\n",
    "# Output: {'loading_progress': 100%}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##prepare data for dabase and upload\n",
    "with open('Product_data.json','r') as f:\n",
    "    products = json.load(f)  \n",
    "\n",
    "data = []\n",
    "text = []\n",
    "vector = []\n",
    "for ele in products:\n",
    "    text.append(ele['text'])\n",
    "    vector.append(ele['vector'])\n",
    "\n",
    "data.append(text)\n",
    "data.append(vector)\n",
    "\n",
    "from pymilvus import Collection\n",
    "collection = Collection(\"Products\")      # Get an existing collection.\n",
    "mr = collection.insert(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lists existing collections\n",
    "utility.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load LLM model\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"llama-2-7b-chat.Q2_K.gguf\", model_file=\"llama-2-7b-chat.Q2_K.gguf\",model_type=\"llama\", gpu_layers=0,context_length=4096)\n",
    "\n",
    "# Load the spaCy model for English language\n",
    "spacy_model = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Connect to Milvus server\n",
    "connections.connect(host=\"localhost\", port=\"19530\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = 'What was the conclusion on the discussion about the road contract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run inference in loop for different queries\n",
    "try:\n",
    "    while True:\n",
    "        user_input = input(\"\\nDescribe query (or type 'exit' to quit):\\n\")\n",
    "        print(f\"User input : {user_input}\\n\")\n",
    "\n",
    "        # Exit loop if user types 'exit'\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        # Process user input using spaCy model to get embedding vector\n",
    "        user_input_doc = spacy_model(user_input)\n",
    "        user_vector = user_input_doc.vector[:128].tolist()\n",
    "\n",
    "        # Define search parameters for similarity search\n",
    "        search_params = {\n",
    "            \"metric_type\": \"L2\",\n",
    "            \"offset\": 0, # Number of entities to skip during the search\n",
    "            \"ignore_growing\": False, # Whether to ignore growing segments during similarity searches\n",
    "            \"params\": {\"nprobe\": 1}\n",
    "        }\n",
    "\n",
    "        # Connect to the Milvus collection named \"Products\"\n",
    "        collection = Collection(\"Products\")\n",
    "\n",
    "        # Perform similarity search using Milvus\n",
    "        similarity_search_result = collection.search(\n",
    "            data=[user_vector],\n",
    "            anns_field=\"vector\",\n",
    "            param=search_params,\n",
    "            limit=1,\n",
    "            output_fields=['text']\n",
    "        )\n",
    "\n",
    "        # Display search results to the user\n",
    "        # for idx, hit in enumerate(similarity_search_result[0]):\n",
    "        score = similarity_search_result[0][0].distance\n",
    "        description = similarity_search_result[0][0].entity.text\n",
    "        print(f\"{description} \\ndistance: {score}\\n\")\n",
    "\n",
    "        prompt = f\"Use context to answer the query.\\n context : {description}\\n query:{user_input}\\n answer : \"\n",
    "        input_text = f\"[INST] <<SYS>>You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>[/INST] \\n{prompt}\"\n",
    "        print(f'LLM response : {llm(prompt)}\\n')\n",
    "\n",
    "except MilvusException as e:\n",
    "    # Handle Milvus exceptions\n",
    "    print(e)\n",
    "finally:\n",
    "    # Disconnect from Milvus server\n",
    "    connections.disconnect(alias=\"localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
